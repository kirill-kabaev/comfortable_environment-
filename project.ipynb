{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pictures\\\\picture.bmp', 'pictures\\\\picture2.bmp', 'pictures\\\\Usa_NewYork.bmp']\n",
      "[ INFO ] Creating Inference Engine\n",
      "[ INFO ] Loading network\n",
      "[ INFO ] Preparing input blobs\n",
      "[ WARNING ] Image pictures\\picture.bmp is resized from (672, 1690) to (1024, 2048)\n",
      "[ WARNING ] Image pictures\\picture2.bmp is resized from (586, 1893) to (1024, 2048)\n",
      "[ WARNING ] Image pictures\\Usa_NewYork.bmp is resized from (920, 1474) to (1024, 2048)\n",
      "[ INFO ] Batch size is 3\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference\n",
      "[ INFO ] Processing output blob\n",
      "Resalt raiting:\n",
      " road           0.16897524012046722 \n",
      " sidewalk       0.002092469272719873 \n",
      " building       0.0008311373163485409 \n",
      " wall           0.004716879146147898 \n",
      " fence          0.004716879146147898 \n",
      " pole           0.0 \n",
      " traffic light  0.0 \n",
      " traffic sign   0.00044863609539701275 \n",
      " vegetation     0.3331976720524195 \n",
      " terrain        0.13456825373407677 \n",
      " sky            0.020776525171950673 \n",
      " person         0.0 \n",
      " rider          0.0 \n",
      " car            0.0011955150380529892 \n",
      " truck          0.0 \n",
      " bus            0.0 \n",
      " train          0.0 \n",
      " motorcycle     0.0 \n",
      " bicycle        0.0 \n",
      " ego-vehicle??  0.0 \n",
      " ?????          0.0\n",
      "[ INFO ] Result image was saved to out_0.bmp\n",
      "Resalt raiting:\n",
      " road           0.1280637985657767 \n",
      " sidewalk       0.029527811597662115 \n",
      " building       0.040457186479636344 \n",
      " wall           0.03794404244361567 \n",
      " fence          0.03794404244361567 \n",
      " pole           0.0 \n",
      " traffic light  0.0 \n",
      " traffic sign   0.0002458783183328045 \n",
      " vegetation     0.2984432557166291 \n",
      " terrain        0.07259983872389487 \n",
      " sky            0.06801429171906913 \n",
      " person         0.0 \n",
      " rider          0.0 \n",
      " car            0.012632793109117954 \n",
      " truck          0.0 \n",
      " bus            0.0 \n",
      " train          0.0 \n",
      " motorcycle     0.0 \n",
      " bicycle        0.0 \n",
      " ego-vehicle??  0.0 \n",
      " ?????          0.0\n",
      "[ INFO ] Result image was saved to out_1.bmp\n",
      "Resalt raiting:\n",
      " road           0.08701610558741177 \n",
      " sidewalk       0.01858120020486959 \n",
      " building       0.0704531823939302 \n",
      " wall           0.02483149097359157 \n",
      " fence          0.02483149097359157 \n",
      " pole           0.0 \n",
      " traffic light  0.0 \n",
      " traffic sign   0.0007540514476966801 \n",
      " vegetation     0.33778873465662135 \n",
      " terrain        0.045685476341793714 \n",
      " sky            0.0437214059880779 \n",
      " person         0.0 \n",
      " rider          0.0 \n",
      " car            0.021895174218092645 \n",
      " truck          0.0 \n",
      " bus            0.0007746815543059137 \n",
      " train          0.0 \n",
      " motorcycle     0.0 \n",
      " bicycle        0.0 \n",
      " ego-vehicle??  0.0003621846777672078 \n",
      " ?????          0.0\n",
      "[ INFO ] Result image was saved to out_2.bmp\n",
      "[ INFO ] This demo is an API example, for any performance measurements please use the dedicated benchmark_app tool from the openVINO toolkit\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    " Copyright (C) 2018-2019 Intel Corporation\n",
    "\n",
    " Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    " you may not use this file except in compliance with the License.\n",
    " You may obtain a copy of the License at\n",
    "\n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    " Unless required by applicable law or agreed to in writing, software\n",
    " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    " See the License for the specific language governing permissions and\n",
    " limitations under the License.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "#from argparse import ArgumentParser, SUPPRESS\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging as log\n",
    "from time import time\n",
    "from openvino.inference_engine import IECore\n",
    "import glob\n",
    "def class_size(cl1,cl2,cl3,cl4,cl5,cl6,cl7,cl8,cl9,cl10,cl11,cl12,cl13,cl14,cl15,cl16,cl17,cl18,cl19,cl20,cl21):\n",
    "    sum_cl=cl1+cl2+cl3+cl4+cl5+cl6+cl7+cl8+cl9+cl10+cl11+cl12+cl13+cl14+cl15+cl16+cl17+cl18+cl9+cl20+cl21\n",
    "    cl1_ratio=cl1/sum_cl\n",
    "    cl2_ratio=cl2/sum_cl\n",
    "    cl3_ratio=cl3/sum_cl\n",
    "    cl4_ratio=cl5/sum_cl\n",
    "    cl5_ratio=cl5/sum_cl\n",
    "    cl6_ratio=cl6/sum_cl\n",
    "    cl7_ratio=cl7/sum_cl\n",
    "    cl8_ratio=cl8/sum_cl\n",
    "    cl9_ratio=cl9/sum_cl\n",
    "    cl10_ratio=cl10/sum_cl\n",
    "    cl11_ratio=cl11/sum_cl\n",
    "    cl12_ratio=cl12/sum_cl\n",
    "    cl13_ratio=cl13/sum_cl\n",
    "    cl14_ratio=cl14/sum_cl\n",
    "    cl15_ratio=cl15/sum_cl\n",
    "    cl16_ratio=cl16/sum_cl\n",
    "    cl17_ratio=cl17/sum_cl\n",
    "    cl18_ratio=cl18/sum_cl\n",
    "    cl19_ratio=cl19/sum_cl\n",
    "    cl20_ratio=cl20/sum_cl\n",
    "    cl21_ratio=cl21/sum_cl\n",
    "    print(\"Resalt raiting:\"\n",
    "          \"\\n road          \",cl1_ratio,\n",
    "          \"\\n sidewalk      \", cl2_ratio,\n",
    "          \"\\n building      \", cl3_ratio,\n",
    "          \"\\n wall          \", cl4_ratio,\n",
    "          \"\\n fence         \", cl5_ratio,\n",
    "          \"\\n pole          \", cl6_ratio,\n",
    "          \"\\n traffic light \", cl7_ratio,\n",
    "          \"\\n traffic sign  \", cl8_ratio,\n",
    "          \"\\n vegetation    \", cl9_ratio,\n",
    "          \"\\n terrain       \", cl10_ratio,\n",
    "          \"\\n sky           \", cl11_ratio,\n",
    "          \"\\n person        \", cl12_ratio,\n",
    "          \"\\n rider         \", cl13_ratio,\n",
    "          \"\\n car           \", cl14_ratio,\n",
    "          \"\\n truck         \", cl15_ratio,\n",
    "          \"\\n bus           \", cl16_ratio,\n",
    "          \"\\n train         \", cl17_ratio,\n",
    "          \"\\n motorcycle    \", cl18_ratio,\n",
    "          \"\\n bicycle       \", cl19_ratio,\n",
    "          \"\\n ego-vehicle?? \", cl20_ratio,\n",
    "          \"\\n ?????         \", cl21_ratio)\n",
    "\n",
    "classes_color_map = [\n",
    "    (150, 150, 150),# road (и вода тут) cl1\n",
    "    (58, 55, 169),#sidewalk(бордюр,брусчатка) cl2\n",
    "    (211, 51, 17),#building (и мосты тут) cl3\n",
    "    (157, 80, 44),# wall(ограждения, шлагбаум)cl4\n",
    "    (23, 95, 189),#fence(большой забор,ограждения мостов)cl5\n",
    "    (210, 133, 34),#pole(столбы,фонари)cl6\n",
    "    (76, 226, 202),#traffic light cl7\n",
    "    (101, 138, 127),#traffic sign (очень плохо) cl8\n",
    "    (223, 91, 182),#vegetation(только деревья, без травы) cl9\n",
    "    (80, 128, 113),#terrain(трава,снег)cl10\n",
    "    (235, 155, 55),#sky cl11\n",
    "    (44, 151, 243),#person cl12\n",
    "    (159, 80, 170),#rider?? cl13\n",
    "    (239, 208, 44),#car cl14\n",
    "    (128, 50, 51),#truck cl15\n",
    "    (82, 141, 193),#bus cl16\n",
    "    (9, 107, 10),#train cl17\n",
    "    (223, 90, 142),#motorcycle cl18\n",
    "    (50, 248, 83),#bicycle cl19\n",
    "    (178, 101, 130),#ego-vehicle??? cl20\n",
    "    (71, 30, 204),#????? cl21\n",
    "]\n",
    "#N = len(classes_color_map)\n",
    "\n",
    "\"\"\"\n",
    "def build_argparser():\n",
    "    parser = ArgumentParser(add_help=False)\n",
    "    args = parser.add_argument_group('Options')\n",
    "    args.add_argument('-h', '--help', action='help', default=SUPPRESS, help='Show this help message and exit.')\n",
    "    args.add_argument(\"-m\", \"--model\", help=\"Required. Path to an .xml file with a trained model\",\n",
    "                      required=True, type=str)\n",
    "    args.add_argument(\"-i\", \"--input\", help=\"Required. Path to a folder with images or path to an image files\",\n",
    "                      required=True, type=str, nargs=\"+\")\n",
    "    args.add_argument(\"-l\", \"--cpu_extension\",\n",
    "                      help=\"Optional. Required for CPU custom layers. \"\n",
    "                           \"Absolute MKLDNN (CPU)-targeted custom layers. Absolute path to a shared library with the \"\n",
    "                           \"kernels implementations\", type=str, default=None)\n",
    "    args.add_argument(\"-d\", \"--device\",\n",
    "                      help=\"Optional. Specify the target device to infer on; CPU, GPU, FPGA, HDDL or MYRIAD is \"\n",
    "                           \"acceptable. Sample will look for a suitable plugin for device specified. Default value is CPU\",\n",
    "                      default=\"CPU\", type=str)\n",
    "    args.add_argument(\"-nt\", \"--number_top\", help=\"Optional. Number of top results\", default=10, type=int)\n",
    "    return parser\n",
    "\"\"\"\n",
    "\n",
    "model = 'semantic-segmentation-adas-0001.xml'\n",
    "cpu_extension=None\n",
    "device='CPU'\n",
    "number_top=10\n",
    "\n",
    "folders = glob.glob('pictures')\n",
    "input = []\n",
    "for folder in folders:\n",
    "       for f in glob.glob(folder+'/*.bmp'):\n",
    "           input.append(f)\n",
    "\n",
    "print(input)\n",
    "\n",
    "def main():\n",
    "    log.basicConfig(format=\"[ %(levelname)s ] %(message)s\", level=log.INFO, stream=sys.stdout)\n",
    "\n",
    "    log.info(\"Creating Inference Engine\")\n",
    "    ie = IECore()\n",
    "    if cpu_extension and 'CPU' in device:\n",
    "        ie.add_extension(cpu_extension, \"CPU\")\n",
    "    # Read IR\n",
    "    log.info(\"Loading network\")\n",
    "    net = ie.read_network(model, os.path.splitext(model)[0] + \".bin\")\n",
    "\n",
    "    if \"CPU\" in device:\n",
    "        supported_layers = ie.query_network(net, \"CPU\")\n",
    "        not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "        if len(not_supported_layers) != 0:\n",
    "            log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                      format(device, ', '.join(not_supported_layers)))\n",
    "            log.error(\"Please try to specify cpu extensions library path in sample's command line parameters using -l \"\n",
    "                      \"or --cpu_extension command line argument\")\n",
    "            sys.exit(1)\n",
    "    assert len(net.inputs.keys()) == 1, \"Sample supports only single input topologies\"\n",
    "    assert len(net.outputs) == 1, \"Sample supports only single output topologies\"\n",
    "\n",
    "    log.info(\"Preparing input blobs\")\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    net.batch_size = len(input)\n",
    "    \n",
    "\n",
    "    # NB: This is required to load the image as uint8 np.array\n",
    "    #     Without this step the input blob is loaded in FP32 precision,\n",
    "    #     this requires additional operation and more memory.\n",
    "    net.inputs[input_blob].precision = \"U8\"\n",
    "\n",
    "    # Read and pre-process input images\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    images = np.ndarray(shape=(n, c, h, w))\n",
    "    for i in range(n):\n",
    "        image = cv2.imread(input[i])\n",
    "        assert image.dtype == np.uint8\n",
    "        if image.shape[:-1] != (h, w):\n",
    "            log.warning(\"Image {} is resized from {} to {}\".format(input[i], image.shape[:-1], (h, w)))\n",
    "            image = cv2.resize(image, (w, h))\n",
    "        image = image.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
    "        images[i] = image\n",
    "    log.info(\"Batch size is {}\".format(n))\n",
    "\n",
    "    # Loading model to the plugin\n",
    "    log.info(\"Loading model to the plugin\")\n",
    "    exec_net = ie.load_network(network=net, device_name=device)\n",
    "\n",
    "    # Start sync inference\n",
    "    log.info(\"Starting inference\")\n",
    "    res = exec_net.infer(inputs={input_blob: images})\n",
    "\n",
    "    # Processing output blob\n",
    "    log.info(\"Processing output blob\")\n",
    "    res = res[out_blob]\n",
    "    if len(res.shape) == 3:\n",
    "        res = np.expand_dims(res, axis=1)\n",
    "    if len(res.shape) == 4:\n",
    "        _, _, out_h, out_w = res.shape\n",
    "    else:\n",
    "        raise Exception(\"Unexpected output blob shape {}. Only 4D and 3D output blobs are supported\".format(res.shape))  \n",
    "        \n",
    "    #classes=np.zeros(N)\n",
    "    cl1=0\n",
    "    cl2=0\n",
    "    cl3=0\n",
    "    cl4=0\n",
    "    cl5=0\n",
    "    cl6=0\n",
    "    cl7=0\n",
    "    cl8=0\n",
    "    cl9=0\n",
    "    cl10=0\n",
    "    cl11=0\n",
    "    cl12=0\n",
    "    cl13=0\n",
    "    cl14=0\n",
    "    cl15=0\n",
    "    cl16=0\n",
    "    cl17=0\n",
    "    cl18=0\n",
    "    cl19=0\n",
    "    cl20=0\n",
    "    cl21=0\n",
    "    for batch, data in enumerate(res):\n",
    "        classes_map = np.zeros(shape=(out_h, out_w, 3), dtype=np.int)\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                if len(data[:, i, j]) == 1:\n",
    "                    pixel_class = int(data[:, i, j])\n",
    "                else:\n",
    "                    pixel_class = np.argmax(data[:, i, j])\n",
    "                classes_map[i, j, :] = classes_color_map[min(pixel_class, 20)] \n",
    "                if min(pixel_class, 20)==0:\n",
    "                    cl1+=1\n",
    "                elif min(pixel_class, 20)==1:\n",
    "                    cl2+=1\n",
    "                elif min(pixel_class, 20)==2:\n",
    "                    cl3+=1\n",
    "                elif min(pixel_class, 20)==3:\n",
    "                    cl4+=1\n",
    "                elif min(pixel_class, 20)==4:\n",
    "                    cl5+=1\n",
    "                elif min(pixel_class, 20)==5:\n",
    "                    cl5+=1\n",
    "                elif min(pixel_class, 20)==6:\n",
    "                    cl7+=1\n",
    "                elif min(pixel_class, 20)==7:\n",
    "                    cl8+=1\n",
    "                elif min(pixel_class, 20)==8:\n",
    "                    cl9+=1\n",
    "                elif min(pixel_class, 20)==9:\n",
    "                    cl10+=1\n",
    "                elif min(pixel_class, 20)==10:\n",
    "                    cl11+=1\n",
    "                elif min(pixel_class, 20)==11:\n",
    "                    cl12+=1\n",
    "                elif min(pixel_class, 20)==12:\n",
    "                    cl13+=1\n",
    "                elif min(pixel_class, 20)==13:\n",
    "                    cl14+=1\n",
    "                elif min(pixel_class, 20)==14:\n",
    "                    cl15+=1\n",
    "                elif min(pixel_class, 20)==15:\n",
    "                    cl16+=1\n",
    "                elif min(pixel_class, 20)==16:\n",
    "                    cl17+=1\n",
    "                elif min(pixel_class, 20)==17:\n",
    "                    cl18+=1\n",
    "                elif min(pixel_class, 20)==18:\n",
    "                    cl19+=1\n",
    "                elif min(pixel_class, 20)==19:\n",
    "                    cl20+=1\n",
    "                else:\n",
    "                    cl21+=1\n",
    "        class_size(cl1,cl2,cl3,cl4,cl5,cl6,cl7,cl8,cl9,cl10,cl11,cl12,cl13,cl14,cl15,cl16,cl17,cl18,cl19,cl20,cl21)\n",
    "        out_img = os.path.join(os.path.dirname('__file__'), \"out_{}.bmp\".format(batch))\n",
    "        cv2.imwrite(out_img, classes_map)\n",
    "        log.info(\"Result image was saved to {}\".format(out_img))\n",
    "    log.info(\"This demo is an API example, for any performance measurements please use the dedicated benchmark_app tool \"\n",
    "             \"from the openVINO toolkit\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.exit(main() or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
